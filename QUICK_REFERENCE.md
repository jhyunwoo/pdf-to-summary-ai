# ë¹ ë¥¸ ì°¸ì¡° ê°€ì´ë“œ

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰

### ìµœì´ˆ ì„¤ì¹˜

```bash
cd /Users/jhyunwoo/projects/pdf-to-summary-ai
chmod +x *.sh
./quick_start.sh
```

### ì¼ìƒì ì¸ ì‚¬ìš©

```bash
# ì„œë²„ ì‹œì‘
source venv/bin/activate
./run_server.sh

# ì„œë²„ ì¢…ë£Œ
./stop_all.sh
```

## ğŸ“ ì£¼ìš” ëª…ë ¹ì–´

### ê°€ìƒí™˜ê²½

```bash
# í™œì„±í™”
source venv/bin/activate

# ë¹„í™œì„±í™”
deactivate

# ì¬ìƒì„±
rm -rf venv && ./setup_venv.sh
```

### Ollama

```bash
# ì„œë²„ ì‹œì‘
./start_ollama.sh

# ì„œë²„ ì¢…ë£Œ
pkill ollama

# ìƒíƒœ í™•ì¸
ps aux | grep ollama
curl http://localhost:11434/api/tags

# ëª¨ë¸ ëª©ë¡
ollama list

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull qwen3-vl:32b

# ëª¨ë¸ ì‚­ì œ
ollama rm qwen3-vl:32b
```

### API ì„œë²„

```bash
# ì‹œì‘
./run_server.sh

# ì¢…ë£Œ
pkill -f "python server.py"

# ìƒíƒœ í™•ì¸
ps aux | grep "python server.py"
lsof -i :8000

# ë¡œê·¸ í™•ì¸
tail -f server.log
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
source venv/bin/activate

# ê¸°ë³¸ í…ŒìŠ¤íŠ¸
python test_client.py

# ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
python test_client.py test.jpg "ì´ë¯¸ì§€ ì„¤ëª…í•´ì¤˜"

# ì˜ˆì œ ì‹¤í–‰
python example_usage.py test.jpg

# cURL í…ŒìŠ¤íŠ¸
curl http://localhost:8000/health
```

## ğŸ” ë¬¸ì œ í•´ê²°

```bash
# í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep -E "ollama|python server.py"

# í¬íŠ¸ í™•ì¸
lsof -i :8000
lsof -i :11434

# ë¡œê·¸ í™•ì¸
cat ollama.log
cat server.log

# ëª¨ë“  ì„œë¹„ìŠ¤ ì¢…ë£Œ
./stop_all.sh

# ì¬ì‹œì‘
./stop_all.sh && ./run_server.sh
```

## ğŸŒ ì ‘ì† ì£¼ì†Œ

- **API ë¬¸ì„œ**: http://localhost:8000/docs
- **í—¬ìŠ¤ì²´í¬**: http://localhost:8000/health
- **Ollama API**: http://localhost:11434

## ğŸ“Š í™˜ê²½ ë³€ìˆ˜

```bash
export OLLAMA_HOST=http://localhost:11434
export MODEL_NAME=qwen3-vl:32b
export PORT=8000
export HOST=0.0.0.0
```

## ğŸ“‚ ì¤‘ìš” íŒŒì¼ ìœ„ì¹˜

- **ê°€ìƒí™˜ê²½**: `venv/`
- **ëª¨ë¸**: `.ollama/models/`
- **ë¡œê·¸**: `ollama.log`, `server.log`
- **ì„¤ì •**: `requirements.txt`, `vessl.yaml`

