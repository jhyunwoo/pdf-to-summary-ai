#!/bin/bash
# Ollama ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ (VESSL í™˜ê²½ìš©)

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

echo "ğŸš€ Ollama ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤..."

# 1. ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
echo "ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´:"
uname -a
echo ""

# 2. GPU í™•ì¸ (NVIDIA GPUê°€ ìˆëŠ” ê²½ìš°)
if command -v nvidia-smi &> /dev/null; then
    echo "ğŸ® GPU ì •ë³´:"
    nvidia-smi
    echo ""
else
    echo "âš ï¸  NVIDIA GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤."
    echo ""
fi

# 3. Ollama ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
echo "ğŸ“¥ Ollama ë‹¤ìš´ë¡œë“œ ì¤‘..."

if [ -f "/usr/local/bin/ollama" ]; then
    echo "âœ… Ollamaê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    /usr/local/bin/ollama --version
else
    # Ollama ì„¤ì¹˜
    curl -fsSL https://ollama.com/install.sh | sh
    
    if [ $? -eq 0 ]; then
        echo "âœ… Ollama ì„¤ì¹˜ ì™„ë£Œ"
        ollama --version
    else
        echo "âŒ Ollama ì„¤ì¹˜ ì‹¤íŒ¨"
        exit 1
    fi
fi

echo ""
echo "ğŸ‰ Ollama ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
echo ""
echo "ë‹¤ìŒ ë‹¨ê³„:"
echo "1. Ollama ì„œë²„ ì‹œì‘: ./start_ollama.sh"
echo "2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ./download_model.sh"
echo "3. Python ì„œë²„ ì‹œì‘: python server.py"

