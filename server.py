"""
Ollama Gemma3 API Server
í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ollamaì˜ gemma3:27b ëª¨ë¸ë¡œ ì²˜ë¦¬í•˜ëŠ” ì„œë²„
"""
import os
import base64
from typing import Optional
from contextlib import asynccontextmanager
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import requests
import json
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv
from sqlalchemy.orm import Session

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# DB ê´€ë ¨ import
from database import get_db, init_db
from models import AnalysisRecord


# ìµœì‹  FastAPI lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    # Startup
    try:
        print("ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        init_db()
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("âš ï¸  DB ê¸°ëŠ¥ ì—†ì´ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. DB ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    yield
    
    # Shutdown
    print("ğŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘...")


app = FastAPI(
    title="Ollama Gemma3 API Server",
    description="í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” Language Model ì„œë²„",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • - ëª¨ë“  origin í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

# Ollama API ì„¤ì •
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434")
MODEL_NAME = os.getenv("MODEL_NAME", "gemma3:27b")


class TextPromptRequest(BaseModel):
    """í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬í•˜ëŠ” ìš”ì²­"""
    prompt: str
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 2000


def encode_image_to_base64(image_bytes: bytes) -> str:
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    return base64.b64encode(image_bytes).decode('utf-8')


def validate_image(image_bytes: bytes) -> bool:
    """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦"""
    try:
        img = Image.open(BytesIO(image_bytes))
        img.verify()
        return True
    except Exception:
        return False


@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "message": "Ollama Gemma3 API Server",
        "model": MODEL_NAME,
        "ollama_host": OLLAMA_HOST
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ë° ollama ì—°ê²° í™•ì¸"""
    try:
        # Ollama ì„œë²„ ì—°ê²° í™•ì¸
        response = requests.get(f"{OLLAMA_HOST}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            model_exists = any(MODEL_NAME in model.get("name", "") for model in models)
            
            return {
                "status": "healthy",
                "ollama_connected": True,
                "model_loaded": model_exists,
                "available_models": [model.get("name") for model in models]
            }
        else:
            return JSONResponse(
                status_code=503,
                content={
                    "status": "unhealthy",
                    "ollama_connected": False,
                    "error": "Ollama server is not responding properly"
                }
            )
    except Exception as e:
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "ollama_connected": False,
                "error": str(e)
            }
        )


class ImageUrlRequest(BaseModel):
    """ì´ë¯¸ì§€ URLë¡œ ìš”ì²­í•˜ëŠ” ëª¨ë¸"""
    image_url: str
    prompt: str
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 2000


def download_image_from_url(url: str) -> bytes:
    """URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        return response.content
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/generate")
async def generate_with_image(request: ImageUrlRequest, db: Session = Depends(get_db)):
    """
    ì´ë¯¸ì§€ URLê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ì„œ Gemma3 ëª¨ë¸ë¡œ ì²˜ë¦¬
    
    Args:
        request: ì´ë¯¸ì§€ URL, í”„ë¡¬í”„íŠ¸, ìƒì„± ì˜µì…˜ì„ í¬í•¨í•œ ìš”ì²­
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # DB ë ˆì½”ë“œ ì´ˆê¸°í™”
    record = AnalysisRecord(
        endpoint="/api/generate",
        prompt=request.prompt,
        has_image=True,
        image_url=request.image_url,
        temperature=request.temperature,
        max_tokens=request.max_tokens,
        model=MODEL_NAME
    )
    
    try:
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_bytes = download_image_from_url(request.image_url)
        
        # ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦
        if not validate_image(image_bytes):
            record.success = False
            record.error_message = "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤."
            db.add(record)
            db.commit()
            raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        image_base64 = encode_image_to_base64(image_bytes)
        
        # Ollama API ìš”ì²­ ì¤€ë¹„
        payload = {
            "model": MODEL_NAME,
            "prompt": request.prompt,
            "images": [image_base64],
            "stream": False,
            "options": {
                "temperature": request.temperature,
                "num_predict": request.max_tokens
            }
        }
        
        # Ollama API í˜¸ì¶œ
        response = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json=payload,
            timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ (í° ëª¨ë¸ì´ë¯€ë¡œ)
        )
        
        if response.status_code != 200:
            record.success = False
            record.error_message = f"Ollama API ì˜¤ë¥˜: {response.text}"
            db.add(record)
            db.commit()
            raise HTTPException(
                status_code=response.status_code,
                detail=f"Ollama API ì˜¤ë¥˜: {response.text}"
            )
        
        result = response.json()
        
        # DBì— ì„±ê³µ ê²°ê³¼ ì €ì¥
        record.response = result.get("response", "")
        record.success = True
        record.total_duration = result.get("total_duration")
        record.load_duration = result.get("load_duration")
        record.prompt_eval_count = result.get("prompt_eval_count")
        record.eval_count = result.get("eval_count")
        db.add(record)
        db.commit()
        db.refresh(record)
        
        return {
            "success": True,
            "response": result.get("response", ""),
            "model": MODEL_NAME,
            "prompt": request.prompt,
            "done": result.get("done", False),
            "context": result.get("context", []),
            "total_duration": result.get("total_duration"),
            "load_duration": result.get("load_duration"),
            "prompt_eval_count": result.get("prompt_eval_count"),
            "eval_count": result.get("eval_count"),
            "record_id": record.id  # DB ë ˆì½”ë“œ ID ì¶”ê°€
        }
        
    except requests.exceptions.Timeout:
        record.success = False
        record.error_message = "Ollama ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼"
        db.add(record)
        db.commit()
        raise HTTPException(status_code=504, detail="Ollama ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
    except requests.exceptions.ConnectionError:
        record.success = False
        record.error_message = "Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        db.add(record)
        db.commit()
        raise HTTPException(status_code=503, detail="Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except HTTPException:
        # HTTPExceptionì€ ì´ë¯¸ ì²˜ë¦¬ë¨
        raise
    except Exception as e:
        record.success = False
        record.error_message = str(e)
        db.add(record)
        db.commit()
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")


@app.post("/api/generate/text")
async def generate_text_only(request: TextPromptRequest, db: Session = Depends(get_db)):
    """
    í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬ (ì´ë¯¸ì§€ ì—†ì´)
    
    Args:
        request: í”„ë¡¬í”„íŠ¸ì™€ ìƒì„± ì˜µì…˜ì„ í¬í•¨í•œ ìš”ì²­
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # DB ë ˆì½”ë“œ ì´ˆê¸°í™”
    record = AnalysisRecord(
        endpoint="/api/generate/text",
        prompt=request.prompt,
        has_image=False,
        temperature=request.temperature,
        max_tokens=request.max_tokens,
        model=MODEL_NAME
    )
    
    try:
        # Ollama API ìš”ì²­ ì¤€ë¹„
        payload = {
            "model": MODEL_NAME,
            "prompt": request.prompt,
            "stream": False,
            "options": {
                "temperature": request.temperature,
                "num_predict": request.max_tokens
            }
        }
        
        # Ollama API í˜¸ì¶œ
        response = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json=payload,
            timeout=300
        )
        
        if response.status_code != 200:
            record.success = False
            record.error_message = f"Ollama API ì˜¤ë¥˜: {response.text}"
            db.add(record)
            db.commit()
            raise HTTPException(
                status_code=response.status_code,
                detail=f"Ollama API ì˜¤ë¥˜: {response.text}"
            )
        
        result = response.json()
        
        # DBì— ì„±ê³µ ê²°ê³¼ ì €ì¥
        record.response = result.get("response", "")
        record.success = True
        record.total_duration = result.get("total_duration")
        record.load_duration = result.get("load_duration")
        record.prompt_eval_count = result.get("prompt_eval_count")
        record.eval_count = result.get("eval_count")
        db.add(record)
        db.commit()
        db.refresh(record)
        
        return {
            "success": True,
            "response": result.get("response", ""),
            "model": MODEL_NAME,
            "prompt": request.prompt,
            "done": result.get("done", False),
            "record_id": record.id  # DB ë ˆì½”ë“œ ID ì¶”ê°€
        }
        
    except requests.exceptions.Timeout:
        record.success = False
        record.error_message = "Ollama ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼"
        db.add(record)
        db.commit()
        raise HTTPException(status_code=504, detail="Ollama ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
    except requests.exceptions.ConnectionError:
        record.success = False
        record.error_message = "Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        db.add(record)
        db.commit()
        raise HTTPException(status_code=503, detail="Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except HTTPException:
        # HTTPExceptionì€ ì´ë¯¸ ì²˜ë¦¬ë¨
        raise
    except Exception as e:
        record.success = False
        record.error_message = str(e)
        db.add(record)
        db.commit()
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")


@app.get("/api/records")
async def get_analysis_records(
    skip: int = 0,
    limit: int = 100,
    endpoint: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    ì €ì¥ëœ ë¶„ì„ ê¸°ë¡ ì¡°íšŒ
    
    Args:
        skip: ê±´ë„ˆë›¸ ë ˆì½”ë“œ ìˆ˜
        limit: ê°€ì ¸ì˜¬ ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜
        endpoint: íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ë¡œ í•„í„°ë§ (ì„ íƒì‚¬í•­)
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ë¶„ì„ ê¸°ë¡ ëª©ë¡
    """
    query = db.query(AnalysisRecord)
    
    if endpoint:
        query = query.filter(AnalysisRecord.endpoint == endpoint)
    
    records = query.order_by(AnalysisRecord.created_at.desc()).offset(skip).limit(limit).all()
    
    return {
        "success": True,
        "total": query.count(),
        "records": [record.to_dict() for record in records]
    }


@app.get("/api/records/{record_id}")
async def get_analysis_record(record_id: int, db: Session = Depends(get_db)):
    """
    íŠ¹ì • ë¶„ì„ ê¸°ë¡ ì¡°íšŒ
    
    Args:
        record_id: ì¡°íšŒí•  ë ˆì½”ë“œ ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ë¶„ì„ ê¸°ë¡ ìƒì„¸ ì •ë³´
    """
    record = db.query(AnalysisRecord).filter(AnalysisRecord.id == record_id).first()
    
    if not record:
        raise HTTPException(status_code=404, detail="ë ˆì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return {
        "success": True,
        "record": record.to_dict()
    }


class ImageUrlStreamRequest(BaseModel):
    """ì´ë¯¸ì§€ URL ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ëª¨ë¸"""
    image_url: str
    prompt: str
    temperature: Optional[float] = 0.7


@app.post("/api/generate/stream")
async def generate_with_image_stream(request: ImageUrlStreamRequest, db: Session = Depends(get_db)):
    """
    ì´ë¯¸ì§€ URLê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ì„œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ
    (ì‹¤ì‹œê°„ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°›ì•„ë³¼ ìˆ˜ ìˆìŒ)
    """
    # DB ë ˆì½”ë“œ ì´ˆê¸°í™”
    record = AnalysisRecord(
        endpoint="/api/generate/stream",
        prompt=request.prompt,
        has_image=True,
        image_url=request.image_url,
        temperature=request.temperature,
        model=MODEL_NAME
    )
    
    try:
        from fastapi.responses import StreamingResponse
        
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_bytes = download_image_from_url(request.image_url)
        
        # ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦
        if not validate_image(image_bytes):
            record.success = False
            record.error_message = "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤."
            db.add(record)
            db.commit()
            raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        image_base64 = encode_image_to_base64(image_bytes)
        
        # Ollama API ìš”ì²­ ì¤€ë¹„
        payload = {
            "model": MODEL_NAME,
            "prompt": request.prompt,
            "images": [image_base64],
            "stream": True,
            "options": {
                "temperature": request.temperature
            }
        }
        
        def generate():
            """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ë° DBì— ì €ì¥"""
            full_response = []
            last_metrics = {}
            
            try:
                response = requests.post(
                    f"{OLLAMA_HOST}/api/generate",
                    json=payload,
                    stream=True,
                    timeout=300
                )
                
                for line in response.iter_lines():
                    if line:
                        try:
                            chunk_data = json.loads(line)
                            # ì‘ë‹µ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                            if "response" in chunk_data:
                                full_response.append(chunk_data["response"])
                            # ë©”íŠ¸ë¦­ ì •ë³´ ìˆ˜ì§‘
                            if chunk_data.get("done"):
                                last_metrics = chunk_data
                        except json.JSONDecodeError:
                            pass
                        
                        yield line + b'\n'
                
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ DBì— ì €ì¥
                record.response = "".join(full_response)
                record.success = True
                record.total_duration = last_metrics.get("total_duration")
                record.load_duration = last_metrics.get("load_duration")
                record.prompt_eval_count = last_metrics.get("prompt_eval_count")
                record.eval_count = last_metrics.get("eval_count")
                db.add(record)
                db.commit()
                
            except Exception as e:
                record.success = False
                record.error_message = str(e)
                record.response = "".join(full_response) if full_response else None
                db.add(record)
                db.commit()
                yield json.dumps({"error": str(e)}).encode() + b'\n'
        
        return StreamingResponse(
            generate(),
            media_type="application/x-ndjson"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        record.success = False
        record.error_message = str(e)
        db.add(record)
        db.commit()
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("PORT", 3000))
    host = os.getenv("HOST", "0.0.0.0")
    
    print(f"ğŸš€ Ollama Gemma3 API Server ì‹œì‘")
    print(f"ğŸ“ ì„œë²„ ì£¼ì†Œ: http://{host}:{port}")
    print(f"ğŸ¤– ëª¨ë¸: {MODEL_NAME}")
    print(f"ğŸ”— Ollama í˜¸ìŠ¤íŠ¸: {OLLAMA_HOST}")
    print(f"ğŸ“š API ë¬¸ì„œ: http://{host}:{port}/docs")
    
    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info"
    )

